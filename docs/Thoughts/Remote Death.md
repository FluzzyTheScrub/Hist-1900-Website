#IntelligentMachines  #ai #WarfareAndTech #ForTheFuture #atomic 
An extremely pressing topic in the world of ai and ethics is the topic of autonomous weaponry. Authors M Pellegrino, & R Kelly describe this issue within [[@Intelligent machines and the growing importance of ethics]]:

>Most generals, admirals and air marshals – at least within NATO – are all too aware of the political risks of employing lethal autonomous weapons and thus shy away from this technology. This does not mean that this technology will not be developed or adopted, but at this stage it is blinding most observers to much more pressing and important challenges and risks – even when it comes to ethics.
>[[@Intelligent machines and the growing importance of ethics]] Pg 53

The concept of allowing ai to control weaponry is incredibly close to becoming a reality, given that some modern weaponry such as military drones already operate with minimal human input. Some may even consider ai controlled weaponry beneficial, since it saves on the training of soldiers, and puts less human lives at risk.

![[Pasted image 20230404235047.png]]
https://en.wikipedia.org/wiki/Unmanned_combat_aerial_vehicle

However, many ethical dilemnas still surround this potential idea. A primary issue is that this kind of warfare would entirely remove the concept of responsibility that even the modern drones today still have. Even in the case of the most destructive weapons, there is some person on the other end pushing a button, or pulling a trigger, knowing a life is to be taken. Removing this element completely degrades the responsibility of the action, which could lead to cruel acts being performed without regard.

Additionally, ai war machines remove the human element from war, where often times ethical decisions must be made in combat situations in order to save lives on either sides of the war, however ai would not have such decision making capabilities. In some cases, ai may cause even more death, as determining the difference between a combatant, civillian, or even possibly an ally is difficult even for humans. 

Even in the case of some algorithm being programmed to determine which targets to attack, ai has historically been show to [[Biases in Ai| inherit human biases]], and may still not be trustworthy.

Additional information of wartime tech can be found in [[Wartime Tech]]

2023-04-04